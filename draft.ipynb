{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist=fetch_openml('mnist_784',version=1)\n",
    "mnist.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=mnist[\"data\"],mnist[\"target\"]\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "some_digit = X.iloc[0]\n",
    "some_digit_array = np.array(some_digit)  # Convert Series to NumPy array\n",
    "some_digit_image = some_digit_array.reshape(28, 28)\n",
    "\n",
    "plt.imshow(some_digit_image, cmap=\"binary\")\n",
    "plt.axis(\"off\")  # Turn off axis\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:60000]\t#training set 60k\n",
    "X_test = X[60000:]\t#testing set 10k\n",
    "y_train = y[:60000]\t#training set label \n",
    "y_test = y[60000:]\t#testing set label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_5 = (y_train == '5')\n",
    "y_test_5 = (y_test == '5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "sgd_clf.fit (X_train,y_train_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf.predict([some_digit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score(sgd_clf,X_train,y_train_5, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Cross Validation (Self Implementation)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "\n",
    "skfolds = StratifiedKFold(n_splits=3)\n",
    "\n",
    "for train_index, test_index in skfolds.split(X_train, y_train_5):\n",
    "    clone_clf = clone(sgd_clf)\n",
    "    X_train_folds = X_train.iloc[train_index]\n",
    "    y_train_folds = y_train_5.iloc[train_index]\n",
    "    X_test_fold = X_train.iloc[test_index]\n",
    "    y_test_fold = y_train_5.iloc[test_index]\n",
    "    \n",
    "    \n",
    "    clone_clf.fit(X_train_folds,y_train_folds)\n",
    "    y_pred = clone_clf.predict(X_test_fold)\n",
    "    n_correct = sum(y_pred == y_test_fold)\n",
    "    print (n_correct / len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "dummy_clf = DummyClassifier()\n",
    "dummy_clf.fit(X_train, y_train_5)\n",
    "print (any(dummy_clf.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(dummy_clf, X_train, y_train_5 ,cv=3,scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "cross_val_predict(sgd_clf,X_train,y_train_5, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "y_train_pred = cross_val_predict(sgd_clf,X_train,y_train_5, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_train_5,y_train_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_perfect_predection = y_train_5\n",
    "confusion_matrix(y_train_5,y_train_perfect_predection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score , recall_score\n",
    "\n",
    "precision_score(y_train_5,y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm[1,1]/(cm[0,1]+cm[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score (y_train_5,y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm[1,1] / (cm[1,0] + cm[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precisions,recalls,thresholds = precision_recall_curve(y_train_5,y_train_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **new notbook**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "# **Import necessary libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the dataset\n",
    "plant_data = pd.read_csv('plant_disease_data.csv')\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(plant_data.info())\n",
    "print(plant_data.describe())\n",
    "\n",
    "# Display the number of classes and distribution of classes\n",
    "print(\"Number of classes:\", plant_data['label'].nunique())\n",
    "print(\"Distribution of classes:\\n\", plant_data['label'].value_counts())\n",
    "\n",
    "# Function to preprocess the images\n",
    "def preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image, (128, 128))\n",
    "    image = image / 255.0  # Normalize the image\n",
    "    return image\n",
    "\n",
    "# Apply preprocessing to the dataset\n",
    "plant_data['image'] = plant_data['image_path'].apply(preprocess_image)\n",
    "\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the dataset\n",
    "plant_data = pd.read_csv('plant_disease_data.csv')\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(plant_data.info())\n",
    "print(plant_data.describe())\n",
    "\n",
    "# Display the number of classes and distribution of classes\n",
    "print(\"Number of classes:\", plant_data['label'].nunique())\n",
    "print(\"Distribution of classes:\\n\", plant_data['label'].value_counts())\n",
    "\n",
    "# Function to preprocess the images\n",
    "def preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image, (128, 128))\n",
    "    image = image / 255.0  # Normalize the image\n",
    "    return image\n",
    "\n",
    "# Apply preprocessing to the dataset\n",
    "plant_data['image'] = plant_data['image_path'].apply(preprocess_image)\n",
    "\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract images and labels\n",
    "X = np.array(plant_data['image'].tolist())\n",
    "y = plant_data['label'].values\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "print(\"Training set size:\", len(X_train))\n",
    "print(\"Test set size:\", len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design a CNN architecture\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and train the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), \n",
    "              loss=SparseCategoricalCrossentropy(), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(datagen.flow(X_train, y_train, batch_size=32), \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test set\n",
    "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "\n",
    "# Accuracy and F1-score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1-Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Sample predictions\n",
    "sample_images = X_test[:5]\n",
    "sample_labels = y_test[:5]\n",
    "sample_preds = y_pred[:5]\n",
    "\n",
    "for i in range(len(sample_images)):\n",
    "    plt.imshow(sample_images[i])\n",
    "    plt.title(f\"Actual: {label_encoder.inverse_transform([sample_labels[i]])[0]}, Predicted: {label_encoder.inverse_transform([sample_preds[i]])[0]}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer Learning Consideration\n",
    "Transfer learning involves leveraging a pre-trained model (trained on a large dataset) to improve performance on a target task with limited data. For plant disease classification, a model like ResNet50 pre-trained on ImageNet can be fine-tuned to achieve better performance. It has learned general features that can be beneficial for identifying patterns in plant diseases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with different learning rates\n",
    "learning_rates = [0.001, 0.0001, 0.00001]\n",
    "histories = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), \n",
    "                  loss=SparseCategoricalCrossentropy(), \n",
    "                  metrics=['accuracy'])\n",
    "    history = model.fit(datagen.flow(X_train, y_train, batch_size=32), \n",
    "                        validation_data=(X_test, y_test), \n",
    "                        epochs=10)\n",
    "    histories.append(history)\n",
    "\n",
    "# Plot training history for different learning rates\n",
    "for i, history in enumerate(histories):\n",
    "    plt.plot(history.history['accuracy'], label=f'LR: {learning_rates[i]}')\n",
    "    \n",
    "plt.title('Effect of Learning Rate on Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **New notbook**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Import necessary libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-06-26T05:46:59.683802Z",
     "iopub.status.busy": "2024-06-26T05:46:59.683439Z",
     "iopub.status.idle": "2024-06-26T05:47:12.180207Z",
     "shell.execute_reply": "2024-06-26T05:47:12.179349Z",
     "shell.execute_reply.started": "2024-06-26T05:46:59.683772Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-26 05:47:01.744920: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-26 05:47:01.745024: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-26 05:47:01.862196: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset and display basic statistics:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-26T05:47:12.182553Z",
     "iopub.status.busy": "2024-06-26T05:47:12.181969Z",
     "iopub.status.idle": "2024-06-26T05:47:13.371889Z",
     "shell.execute_reply": "2024-06-26T05:47:13.369765Z",
     "shell.execute_reply.started": "2024-06-26T05:47:12.182520Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "plant_data = pd.read_csv('plant_disease_data.csv')\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(plant_data.info())\n",
    "print(plant_data.describe())\n",
    "\n",
    "# Display the number of classes and distribution of classes\n",
    "print(\"Number of classes:\", plant_data['label'].nunique())\n",
    "print(\"Distribution of classes:\\n\", plant_data['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the images:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-26T05:47:13.372992Z",
     "iopub.status.idle": "2024-06-26T05:47:13.373434Z",
     "shell.execute_reply": "2024-06-26T05:47:13.373230Z",
     "shell.execute_reply.started": "2024-06-26T05:47:13.373211Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Function to preprocess the images\n",
    "def preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image, (128, 128))\n",
    "    image = image / 255.0  # Normalize the image\n",
    "    return image\n",
    "\n",
    "# Apply preprocessing to the dataset\n",
    "plant_data['image'] = plant_data['image_path'].apply(preprocess_image)\n",
    "\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training and testing sets:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-26T05:47:13.374434Z",
     "iopub.status.idle": "2024-06-26T05:47:13.374770Z",
     "shell.execute_reply": "2024-06-26T05:47:13.374619Z",
     "shell.execute_reply.started": "2024-06-26T05:47:13.374605Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming 'image' column has preprocessed images and 'label' column has labels\n",
    "X = np.array(plant_data['image'].tolist())\n",
    "y = plant_data['label'].values\n",
    "\n",
    "# Encode labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "print(\"Training set size:\", len(X_train))\n",
    "print(\"Test set size:\", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Design a CNN architecture:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-26T05:47:13.375702Z",
     "iopub.status.idle": "2024-06-26T05:47:13.376057Z",
     "shell.execute_reply": "2024-06-26T05:47:13.375897Z",
     "shell.execute_reply.started": "2024-06-26T05:47:13.375867Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile and train the model:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-26T05:47:13.378341Z",
     "iopub.status.idle": "2024-06-26T05:47:13.378786Z",
     "shell.execute_reply": "2024-06-26T05:47:13.378582Z",
     "shell.execute_reply.started": "2024-06-26T05:47:13.378564Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), \n",
    "              loss=SparseCategoricalCrossentropy(), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(datagen.flow(X_train, y_train, batch_size=32), \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    epochs=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-26T05:47:13.380078Z",
     "iopub.status.idle": "2024-06-26T05:47:13.380515Z",
     "shell.execute_reply": "2024-06-26T05:47:13.380303Z",
     "shell.execute_reply.started": "2024-06-26T05:47:13.380285Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Predictions on test set\n",
    "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "\n",
    "# Accuracy and F1-score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1-Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the model's performance:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-26T05:47:13.382158Z",
     "iopub.status.idle": "2024-06-26T05:47:13.382605Z",
     "shell.execute_reply": "2024-06-26T05:47:13.382385Z",
     "shell.execute_reply.started": "2024-06-26T05:47:13.382366Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Sample predictions\n",
    "sample_images = X_test[:5]\n",
    "sample_labels = y_test[:5]\n",
    "sample_preds = y_pred[:5]\n",
    "\n",
    "for i in range(len(sample_images)):\n",
    "    plt.imshow(sample_images[i])\n",
    "    plt.title(f\"Actual: {label_encoder.inverse_transform([sample_labels[i]])[0]}, Predicted: {label_encoder.inverse_transform([sample_preds[i]])[0]}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the impact of adjusting the learning rate:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-26T05:47:13.384434Z",
     "iopub.status.idle": "2024-06-26T05:47:13.384775Z",
     "shell.execute_reply": "2024-06-26T05:47:13.384632Z",
     "shell.execute_reply.started": "2024-06-26T05:47:13.384618Z"
    }
   },
   "outputs": [],
   "source": [
    "# Example with different learning rates\n",
    "learning_rates = [0.001, 0.0001, 0.00001]\n",
    "histories = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), \n",
    "                  loss=SparseCategoricalCrossentropy(), \n",
    "                  metrics=['accuracy'])\n",
    "    history = model.fit(datagen.flow(X_train, y_train, batch_size=32), \n",
    "                        validation_data=(X_test, y_test), \n",
    "                        epochs=10)\n",
    "    histories.append(history)\n",
    "\n",
    "# Plot training history for different learning rates\n",
    "for i, history in enumerate(histories):\n",
    "    plt.plot(history.history['accuracy'], label=f'LR: {learning_rates[i]}')\n",
    "    \n",
    "plt.title('Effect of Learning Rate on Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30664,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
